# Korean Essay Auto-Scoring System with KoBERT and GRU

한국어 에세이 자동 채점 시스템으로, KoBERT 임베딩과 다양한 GRU 아키텍처를 활용하여 에세이를 11개 루브릭 기준으로 평가합니다.

## 🔥 주요 특징

- **KoBERT 기반 임베딩**: 한국어 에세이의 의미적 표현 학습
- **다층 GRU 아키텍처**: 4가지 모델 변형으로 성능 비교
- **UKTA 피처 통합**: 294개의 언어학적 특징을 활용한 하이브리드 모델
- **어텐션 메커니즘**: UKTA 피처에 대한 가중치 학습
- **11개 루브릭 평가**: 문법, 어휘, 구성, 내용 등 포괄적 채점

## 📊 실험 결과

### 모델 성능 비교

| 모델 | Prompt 사용 | 평균 QWK | 상세 성능 |
|------|-------------|----------|-----------|
| Baseline | ❌ | **0.5284** | 기본 GRU 모델 |
| Baseline | ✅ | **0.5499** | 프롬프트 라벨링 추가 |
| GRU + LayerNorm | ✅ | **0.5984** | 정규화 및 평균 풀링 |
| GRU + LayerNorm + UKTA | ✅ | **0.6288** | 🏆 **최고 성능** |
| GRU + LayerNorm + UKTA + Attention | ✅ | **0.6242** | 어텐션 메커니즘 |

### 평가자 간 일치도 (Inter-Rater Reliability)

| 루브릭 | Rater A-B | Rater B-C | Rater C-A | 평균 |
|--------|-----------|-----------|-----------|------|
| exp-grammar | 0.4425 | 0.4283 | 0.3544 | **0.4084** |
| exp-vocab | 0.4696 | 0.5207 | 0.4699 | **0.4867** |
| exp-sentence | **0.9015** | **0.9196** | **0.9103** | **0.9105** |
| org-InterParagraph | 0.5547 | 0.5925 | 0.5589 | **0.5687** |
| org-InParagraph | **0.9199** | **0.9184** | **0.9161** | **0.9181** |
| org-consistency | **0.8873** | **0.8716** | **0.8704** | **0.8764** |
| org-length | **0.7410** | **0.6700** | **0.6115** | **0.6742** |
| cont-clarity | 0.5698 | 0.5756 | 0.4462 | **0.5305** |
| cont-novelty | 0.5317 | 0.4200 | 0.4194 | **0.4570** |
| cont-description | 0.6013 | 0.5487 | 0.5091 | **0.5530** |
| **전체 평균** | **0.6619** | **0.6465** | **0.6066** | **0.6383** |

### 모델-평가자 일치도 (Model-Rater Agreement)
*GRU+LayerNorm+UKTA+Attention 모델 기준*

| 루브릭 | Model-Rater A | Model-Rater B | Model-Rater C | 평균 | 인간 평가자 평균 |
|--------|---------------|---------------|---------------|------|-----------------|
| exp-grammar | 0.3097 | 0.2698 | 0.2333 | **0.2709** | 0.4084 |
| exp-vocab | 0.3585 | 0.3152 | 0.2576 | **0.3104** | 0.4867 |
| exp-sentence | **0.9046** | **0.9025** | **0.9172** | **0.9081** | 0.9105 |
| org-InterParagraph | 0.4543 | 0.4305 | 0.4537 | **0.4462** | 0.5687 |
| org-InParagraph | **0.9097** | **0.9216** | **0.9156** | **0.9156** | 0.9181 |
| org-consistency | **0.8831** | **0.8789** | **0.8636** | **0.8752** | 0.8764 |
| org-length | **0.7523** | **0.7662** | **0.7069** | **0.7418** | 0.6742 |
| cont-clarity | 0.3983 | 0.4604 | 0.3566 | **0.4051** | 0.5305 |
| cont-novelty | 0.3122 | 0.3540 | 0.2844 | **0.3169** | 0.4570 |
| cont-description | 0.5508 | 0.5717 | 0.5050 | **0.5425** | 0.5530 |
| **전체 평균** | **0.5833** | **0.5871** | **0.5494** | **0.5733** | **0.6383** |

### 종합 성능 분석

| 루브릭 | 모델 성능 (QWK) | 인간 평가자 일치도 | 모델-평가자 일치도 | 성능 지표* | 특징 |
|--------|-----------------|-------------------|-------------------|------------|------|
| exp-sentence | **0.9203** | **0.9105** | **0.9081** | 101.1% / 99.7% | 🟢 모든 지표에서 우수 |
| org-InParagraph | **0.9339** | **0.9181** | **0.9156** | 101.7% / 99.7% | 🟢 모든 지표에서 우수 |
| org-consistency | **0.8899** | **0.8764** | **0.8752** | 101.5% / 99.9% | 🟢 모든 지표에서 우수 |
| org-length | **0.8163** | **0.6742** | **0.7418** | 121.1% / 110.0% | 🟢 모델이 일관된 평가 |
| cont-description | 0.6207 | 0.5530 | 0.5425 | 112.2% / 98.1% | 🟡 양호한 성능 |
| org-InterParagraph | 0.4801 | 0.5687 | 0.4462 | 84.4% / 78.5% | 🟡 개선 가능 |
| cont-clarity | 0.5071 | 0.5305 | 0.4051 | 95.6% / 76.4% | 🟡 개선 가능 |
| exp-vocab | 0.3781 | 0.4867 | 0.3104 | 77.7% / 63.8% | 🔴 성능 개선 필요 |
| cont-novelty | 0.4330 | 0.4570 | 0.3169 | 94.7% / 69.3% | 🔴 성능 개선 필요 |
| exp-grammar | 0.3083 | 0.4084 | 0.2709 | 75.5% / 66.3% | 🔴 성능 개선 필요 |

*성능 지표 = (모델 QWK / 인간 일치도) / (모델-평가자 일치도 / 인간 일치도)

### 모델 신뢰성 분석

| 구분 | 전체 평균 QWK | 설명 |
|------|---------------|------|
| **인간 평가자 간 일치도** | **0.6383** | 인간 평가자들 간의 기준선 |
| **모델 성능** | **0.6288** | 실제 라벨과 모델 예측의 일치도 |
| **모델-평가자 일치도** | **0.5733** | 개별 평가자와 모델의 평균 일치도 |
| **신뢰성 지수*** | **89.8%** | 모델-평가자 일치도 / 인간 평가자 일치도 |

*신뢰성 지수: 100%에 가까울수록 모델이 개별 평가자와 인간 평가자들만큼 일치

## 🏗️ 시스템 아키텍처

### 1. 데이터 전처리
```
원본 에세이 → 문장 분리 → (선택적) 주제 라벨 추가 → KoBERT 토크나이징
```

### 2. 모델 구조
```
KoBERT Embedding (768dim) → Bidirectional GRU → Feature Fusion → Scoring
                                    ↓
                            UKTA Features (294dim) → Linear → Concat
```

### 3. 4가지 모델 변형

#### Baseline
- 기본 단방향 GRU
- 마지막 히든 스테이트 사용
- UKTA 피처 미사용

#### GRU with LayerNorm
- 2층 양방향 GRU
- LayerNorm 정규화
- 평균 풀링 적용

#### GRU with LayerNorm + UKTA
- UKTA 언어학적 피처 통합
- 피처 차원 축소 후 결합
- **최고 성능 달성**

#### GRU with LayerNorm + UKTA + Attention
- UKTA 피처에 어텐션 메커니즘 적용
- 동적 피처 가중치 학습

## 📁 파일 구조

```
├── config.py                      # 설정 및 피처 목록
├── embedding.py                   # KoBERT 임베딩 생성
├── kobert_gru_with_features.py    # 메인 모델 학습 코드
├── performance.py                 # 성능 평가 스크립트
├── dataset/
│   └── dataset_with_features.csv  # 원본 데이터셋
├── emb/                           # 임베딩 파일 저장소
├── results/                       # 결과 저장소
└── [모델명]/                      # 각 모델별 결과
    ├── topic_model.pth           # 학습된 모델
    ├── topic_y_pred_.npy         # 예측 결과
    ├── topic_y_true_.npy         # 실제 라벨
    └── attention.npy             # 어텐션 가중치 (해당시)
```

## 🚀 사용법

### 1. 환경 설정
```bash
pip install torch kobert-transformers pandas scikit-learn tqdm dask
```

### 2. 임베딩 생성
```bash
python embedding.py
```

### 3. 모델 학습
```python
# config.py에서 모드 변경
config["mode"] = "gru_with_ln_ukta"  # 원하는 모델 선택
config["is_topic_label"] = True      # 프롬프트 라벨 사용 여부

python kobert_gru_with_features.py
```

### 4. 성능 평가
```bash
python performance.py
```

## 🎯 핵심 기술

### KoBERT 임베딩
- 한국어 특화 BERT 모델 사용
- 문장별 768차원 벡터 생성
- 프롬프트 라벨링으로 맥락 정보 강화

### UKTA 피처 (294개)
- **어휘 다양성**: TTR, RTTR, CTTR, MSTTR 등
- **품사별 분포**: 명사, 동사, 형용사 등 세부 분석
- **텍스트 응집성**: 인접 문장 간 어휘 중복도
- **구조적 특징**: 문단/문장/단어/형태소 개수

### 어텐션 메커니즘
```python
# UKTA 피처에 대한 동적 가중치 계산
attention_scores = self.attention_weights(gru_output)
attention_weights = F.softmax(attention_scores, dim=-1)
weighted_features = ukta_features * attention_weights
```

## 📈 성능 향상 포인트

1. **프롬프트 라벨링**: 기본 모델 대비 +0.0215 QWK 향상
2. **LayerNorm + 평균 풀링**: 안정적인 학습과 일반화 성능 개선
3. **UKTA 피처 통합**: 언어학적 특징으로 +0.0304 QWK 향상
4. **구조적 루브릭 우수성**: 문장/단락 구성 평가에서 0.9+ QWK 달성

## ⚙️ 하이퍼파라미터

```python
dropout = 0.305
learning_rate = 9.15e-4
epochs = 100
hidden_dim = 128
batch_size = 128
patience = 10  # Early stopping
max_length = 400  # 토큰 최대 길이
```

## 🔍 평가 메트릭

**Quadratic Weighted Kappa (QWK)** 사용
- 순서형 분류에 적합한 메트릭
- 예측 오차의 크기에 따라 가중 페널티 적용
- Cohen's Kappa의 확장으로 더 엄격한 평가

## 📝 주요 발견사항

### 1. 모델 성능 분석
- **UKTA 피처의 효과성**: 언어학적 특징이 딥러닝 모델 성능을 크게 향상 (+0.0304 QWK)
- **어텐션의 한계**: 복잡한 어텐션보다 단순한 피처 결합이 더 효과적
- **프롬프트 라벨링 효과**: 주제 정보 추가로 일관된 성능 향상 (+0.0215 QWK)

### 2. 신뢰성 평가 (3-Layer Analysis)
- **모델 성능 (0.6288)** vs **인간 일치도 (0.6383)**: 98.5% 수준으로 거의 동등
- **모델-평가자 일치도 (0.5733)**: 인간 일치도의 89.8% 수준으로 높은 신뢰성
- **구조적 루브릭**: 3개 지표 모두에서 0.87+ 달성으로 가장 안정적

### 3. 루브릭별 특성 분석
- **🟢 High Performance (구조적)**: 
  - exp-sentence, org-InParagraph, org-consistency
  - 모든 지표에서 0.87+ 달성, 규칙 기반 평가 가능
- **🟡 Moderate Performance (내용적)**:
  - org-length, cont-description, org-InterParagraph
  - 모델이 일정 수준 이상 성능, 점진적 개선 가능
- **🔴 Low Performance (언어적)**:
  - exp-grammar, exp-vocab, cont-novelty
  - 모델-평가자 일치도가 인간 일치도의 70% 미만

### 4. 개별 평가자 변동성
- **Rater B**와의 일치도가 가장 높음 (0.5871)
- **Rater C**와의 일치도가 가장 낮음 (0.5494)
- 평가자 간 편차는 있지만, 구조적 루브릭에서는 일관된 고성능 유지

### 5. 모델 신뢰성 검증
- 전체 평균 신뢰성 지수 **89.8%**로 실용적 수준
- 6개 루브릭에서 모델-평가자 일치도가 인간 일치도의 95% 이상
- 언어적 정확성 평가를 제외하면 평가자 수준의 일관성 달성

## 🛠️ 향후 개선 방안

### 단기 개선 과제
- **문법/어휘 평가 강화**: 구문 분석기, 품사 태거 등 언어학적 도구 통합
- **도메인 특화 모델**: 문법 오류 탐지 전용 모델과 앙상블 구성
- **데이터 품질 향상**: 평가자 일치도가 낮은 루브릭의 가이드라인 정교화

### 중장기 연구 방향
- **Transformer 아키텍처** 적용으로 장거리 의존성 포착
- **다중 태스크 학습**으로 루브릭 간 상관관계 활용
- **준지도 학습**을 통한 대규모 미라벨 데이터 활용
- **설명 가능한 AI** 기법으로 채점 근거 제시

### 평가 시스템 개선
- **계층적 평가**: 구조적 → 내용적 → 언어적 순서로 단계별 평가
- **앙상블 전략**: 루브릭별 특화 모델을 조합한 하이브리드 시스템
- **실시간 피드백**: 학습자를 위한 즉시 피드백 시스템 구축

## 📄 License

이 프로젝트는 연구 목적으로 개발되었습니다.

---

*개발자: [Ganghee Go] | 최종 업데이트: 2025년 8월*
