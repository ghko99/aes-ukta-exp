# Korean Essay Auto-Scoring System with KoBERT and GRU
AI-HUB 에세이 글 평가 데이터셋으로 구축한 한국어 에세이 자동 채점 모델로, KoBERT 임베딩과 다양한 GRU 아키텍처를 활용하여 에세이를 11개 루브릭 기준으로 평가합니다.

## 🔥 주요 특징

- **KoBERT 기반 임베딩**: 한국어 에세이의 의미적 표현 학습
- **다층 GRU 아키텍처**: 4가지 모델 변형으로 성능 비교
- **UKTA 피처 통합**: 294개의 언어학적 특징을 활용한 하이브리드 모델
- **어텐션 메커니즘**: UKTA 피처에 대한 가중치 학습
- **11개 루브릭 평가**: 문법, 어휘, 구성, 내용 등 포괄적 채점

## 📊 실험 결과

### 모델 성능 비교

| 모델 | Prompt 사용 | 평균 QWK | 상세 성능 |
|------|-------------|----------|-----------|
| Baseline | ❌ | **0.5284** | 기본 GRU 모델 |
| Baseline | ✅ | **0.5499** | 프롬프트 라벨링 추가 |
| GRU + LayerNorm | ✅ | **0.5984** | 정규화 및 평균 풀링 |
| GRU + LayerNorm + UKTA | ✅ | **0.6288** | 고성능 모델 |
| GRU + LayerNorm + UKTA + Attention | ✅ | **0.6242** | 어텐션 메커니즘 |
| GRU + LayerNorm + UKTA + Attention + Hyperparameter Tuning | ✅ | **0.6506** | 🏆 **최고 성능** |

### 평가자 간 일치도 (Inter-Rater Reliability)

| 루브릭 | Rater A-B | Rater B-C | Rater C-A | 평균 |
|--------|-----------|-----------|-----------|------|
| exp-grammar | 0.4425 | 0.4283 | 0.3544 | **0.4084** |
| exp-vocab | 0.4696 | 0.5207 | 0.4699 | **0.4867** |
| exp-sentence | **0.9015** | **0.9196** | **0.9103** | **0.9105** |
| org-InterParagraph | 0.5547 | 0.5925 | 0.5589 | **0.5687** |
| org-InParagraph | **0.9199** | **0.9184** | **0.9161** | **0.9181** |
| org-consistency | **0.8873** | **0.8716** | **0.8704** | **0.8764** |
| org-length | **0.7410** | **0.6700** | **0.6115** | **0.6742** |
| cont-clarity | 0.5698 | 0.5756 | 0.4462 | **0.5305** |
| cont-novelty | 0.5317 | 0.4200 | 0.4194 | **0.4570** |
| cont-description | 0.6013 | 0.5487 | 0.5091 | **0.5530** |
| **전체 평균** | **0.6619** | **0.6465** | **0.6066** | **0.6383** |

### 모델-평가자 일치도 (Model-Rater Agreement)
*GRU+LayerNorm+UKTA+Attention+Hyperparameter Tuning 모델 기준*

| 루브릭 | Model-Rater A | Model-Rater B | Model-Rater C | 평균 |
|--------|---------------|---------------|---------------|------|
| exp-grammar | 0.3089 | 0.2756 | 0.2333 | **0.2726** |
| exp-vocab | 0.3785 | 0.3576 | 0.2750 | **0.3370** |
| exp-sentence | **0.9061** | **0.9050** | **0.9149** | **0.9087** |
| org-InterParagraph | 0.4980 | 0.4731 | 0.4846 | **0.4852** |
| org-InParagraph | **0.9204** | **0.9233** | **0.9181** | **0.9206** |
| org-consistency | **0.8917** | **0.8822** | **0.8640** | **0.8793** |
| org-length | **0.7705** | **0.7787** | **0.7191** | **0.7561** |
| cont-clarity | 0.4925 | 0.5327 | 0.4117 | **0.4790** |
| cont-novelty | 0.3621 | 0.4005 | 0.3281 | **0.3636** |
| cont-description | 0.5751 | 0.6045 | 0.5191 | **0.5662** |
| **전체 평균** | **0.6104** | **0.6133** | **0.5668** | **0.5968** |


### 종합 성능 분석

| 루브릭 | 모델 성능 (QWK) | 인간 평가자 일치도 | 모델-평가자 일치도 | 성능 지표* | 특징 |
|--------|-----------------|-------------------|-------------------|------------|------|
| exp-sentence | **0.9267** | **0.9105** | **0.9087** | 101.8% / 99.8% | 🟢 모든 지표에서 우수 |
| org-InParagraph | **0.9347** | **0.9181** | **0.9206** | 101.8% / 100.3% | 🟢 모든 지표에서 우수 |
| org-consistency | **0.8978** | **0.8764** | **0.8793** | 102.4% / 100.3% | 🟢 모든 지표에서 우수 |
| org-length | **0.8331** | **0.6742** | **0.7561** | 123.6% / 112.1% | 🟢 모델이 일관된 평가 |
| cont-description | 0.6207 | 0.5530 | 0.5662 | 112.2% / 102.4% | 🟡 양호한 성능 |
| cont-clarity | **0.5583** | 0.5305 | 0.4790 | 105.2% / 90.3% | 🟡 개선된 성능 |
| org-InterParagraph | **0.5271** | 0.5687 | 0.4852 | 92.7% / 85.3% | 🟡 개선 가능 |
| cont-novelty | **0.4428** | 0.4570 | 0.3636 | 96.9% / 79.6% | 🟡 개선된 성능 |
| exp-vocab | **0.4007** | 0.4867 | 0.3370 | 82.3% / 69.2% | 🔴 성능 개선 필요 |
| exp-grammar | **0.3380** | 0.4084 | 0.2726 | 82.8% / 66.7% | 🔴 성능 개선 필요 |

*성능 지표 = (모델 QWK / 인간 일치도) / (모델-평가자 일치도 / 인간 일치도)

### 모델 신뢰성 분석

| 구분 | 전체 평균 QWK | 설명 |
|------|---------------|------|
| **인간 평가자 간 일치도** | **0.6383** | 인간 평가자들 간의 기준선 |
| **모델 성능** | **0.6506** | 실제 라벨과 모델 예측의 일치도 |
| **모델-평가자 일치도** | **0.5968** | 개별 평가자와 모델의 평균 일치도 |
| **신뢰성 지수*** | **93.5%** | 모델-평가자 일치도 / 인간 평가자 일치도 |

*신뢰성 지수: 100%에 가까울수록 모델이 개별 평가자와 인간 평가자들만큼 일치

## 🏗️ 시스템 아키텍처

### 1. 데이터 전처리
```
원본 에세이 → 문장 분리 → (선택적) 주제 라벨 추가 → KoBERT 토크나이징
            ↓
      UKTA 특성 추출 (294dim)
```
### 2. 모델 구조
```
KoBERT 문장별 임베딩 (768dim)               UKTA Features (294dim)
           ↓                                       ↓
    Bidirectional GRU                              │
    (2 layers, dropout)                            │
           ↓                                       │
    Mean Pooling → [B, 2H]                         │
           ↓                                       │
      Layer Norm                                   │
           ↓                                       │
           ├─────────────────────────┐             │
           │                         ↓             │
           │                 Linear(2H → 294)      │
           │                         ↓             │
           │                     Softmax           │
           │                         ↓             │
           │                 Attention Weights ←───┘ (element-wise multiply)
           │                         ↓
           │                Weighted UKTA Features
           │                         ↓
           │                 Linear(294 → H)
           │                         ↓
           └───────→ Concat ←────────┘
                        ↓
       [GRU output(2H) + Weighted UKTA features(H)] → [B, 3H]
                        ↓
                     Dropout
                        ↓
              Linear(3H → output_dim)
                        ↓
                     Sigmoid
                        ↓
                   Final Score
```

### 3. 4가지 모델 변형

#### Baseline
- 기본 단방향 GRU
- 마지막 히든 스테이트 사용
- UKTA 피처 미사용

#### GRU with LayerNorm
- 2층 양방향 GRU
- LayerNorm 정규화
- 평균 풀링 적용

#### GRU with LayerNorm + UKTA
- UKTA 언어학적 피처 통합
- 피처 차원 축소 후 결합

#### GRU with LayerNorm + UKTA + Attention + Hyperparameter Tuning
- UKTA 피처에 어텐션 메커니즘 적용
- 동적 피처 가중치 학습
- **최고 성능 달성 (QWK: 0.6506)**

## 📁 파일 구조

```
├── config.py                      # 설정 및 피처 목록
├── embedding.py                   # KoBERT 임베딩 생성
├── kobert_gru_with_features.py    # 메인 모델 학습 코드
├── performance.py                 # 성능 평가 스크립트
├── dataset/
│   └── dataset_with_features.csv  # 원본 데이터셋
├── emb/                           # 임베딩 파일 저장소
├── results/                       # 결과 저장소
└── [모델명]/                      # 각 모델별 결과
    ├── topic_model.pth           # 학습된 모델
    ├── topic_y_pred_.npy         # 예측 결과
    ├── topic_y_true_.npy         # 실제 라벨
    └── attention.npy             # 어텐션 가중치 (해당시)
```

## 🚀 사용법

### 1. 환경 설정
```bash
pip install torch kobert-transformers pandas scikit-learn tqdm dask
```

### 2. 임베딩 생성
```bash
python embedding.py
```

### 3. 모델 학습
```python
# config.py에서 모드 변경
config["mode"] = "gru_with_ln_ukta_attention"  # 최고 성능 모델 선택
config["is_topic_label"] = True               # 프롬프트 라벨 사용 여부

python kobert_gru_with_features.py
```

### 4. 성능 평가
```bash
python performance.py
```

## 🎯 핵심 기술

### KoBERT 임베딩
- 한국어 특화 BERT 모델 사용
- 문장별 768차원 벡터 생성
- 프롬프트 라벨링으로 맥락 정보 강화

### UKTA 피처 (294개)
- **어휘 다양성**: TTR, RTTR, CTTR, MSTTR 등
- **품사별 분포**: 명사, 동사, 형용사 등 세부 분석
- **텍스트 응집성**: 인접 문장 간 어휘 중복도
- **구조적 특징**: 문단/문장/단어/형태소 개수

### 어텐션 메커니즘
```python
# UKTA 피처에 대한 동적 가중치 계산
attention_scores = self.attention_weights(gru_output)
attention_weights = F.softmax(attention_scores, dim=-1)
weighted_features = ukta_features * attention_weights
```

### 하이퍼파라미터 최적화
- **Optuna** 라이브러리를 활용한 베이지안 최적화
- **9 에포크**에서 최고 성능 달성으로 조기 학습 완료
- 총 **0.0218 QWK 향상** (0.6288 → 0.6506)

## 📈 성능 향상 포인트

1. **프롬프트 라벨링**: 기본 모델 대비 +0.0215 QWK 향상
2. **LayerNorm + 평균 풀링**: 안정적인 학습과 일반화 성능 개선
3. **UKTA 피처 통합**: 언어학적 특징으로 +0.0304 QWK 향상
4. **어텐션 메커니즘**: 동적 피처 가중치로 성능 안정화
5. **하이퍼파라미터 최적화**: 최종 +0.0218 QWK 향상으로 **0.6506** 달성
6. **구조적 루브릭 우수성**: 문장/단락 구성 평가에서 0.9+ QWK 달성

## ⚙️ 최적화된 하이퍼파라미터

```python
# Optuna 최적화 결과 (9 에포크에서 최고 성능)
dropout = 0.15744792172911562
learning_rate = 0.001070028538941047
epochs = 100
hidden_dim = 128
batch_size = 32 
patience = 9  # Early stopping
max_length = 400  # 토큰 최대 길이
```

## 🔍 평가 메트릭

**Quadratic Weighted Kappa (QWK)** 사용
- 순서형 분류에 적합한 메트릭
- 예측 오차의 크기에 따라 가중 페널티 적용
- Cohen's Kappa의 확장으로 더 엄격한 평가

## 📝 주요 발견사항

### 1. 모델 성능 분석
- **하이퍼파라미터 최적화 효과**: 최종 +0.0218 QWK 향상으로 **0.6506** 달성
- **UKTA 피처의 효과성**: 언어학적 특징이 딥러닝 모델 성능을 크게 향상 (+0.0304 QWK)
- **어텐션 메커니즘**: 복잡한 구조보다는 안정적 성능에 기여
- **프롬프트 라벨링 효과**: 주제 정보 추가로 일관된 성능 향상 (+0.0215 QWK)

### 2. 신뢰성 평가 (3-Layer Analysis)
- **모델 성능 (0.6506)** vs **인간 일치도 (0.6383)**: 101.9% 수준으로 인간 평가자 수준 초과
- **모델-평가자 일치도 (0.5968)**: 인간 일치도의 93.5% 수준으로 높은 신뢰성
- **구조적 루브릭**: 3개 지표 모두에서 0.89+ 달성으로 가장 안정적

### 3. 루브릭별 특성 분석
- **🟢 High Performance (구조적)**: 
  - exp-sentence (0.9267), org-InParagraph (0.9347), org-consistency (0.8978), org-length (0.8331)
  - 모든 지표에서 0.83+ 달성, 규칙 기반 평가 가능
- **🟡 Moderate Performance (내용적)**:
  - cont-description (0.6207), cont-clarity (0.5583), org-InterParagraph (0.5271), cont-novelty (0.4428)
  - 모델이 일정 수준 이상 성능, 하이퍼파라미터 최적화로 개선
- **🔴 Low Performance (언어적)**:
  - exp-vocab (0.4007), exp-grammar (0.3380)
  - 여전히 개선이 필요하지만 하이퍼파라미터 최적화로 상당한 향상

### 4. 하이퍼파라미터 최적화 효과
- **조기 학습 완료**: 9 에포크에서 최고 성능 달성으로 효율적 학습
- **전반적 성능 향상**: 모든 루브릭에서 성능 개선 또는 유지
- **특히 개선된 루브릭**: cont-clarity (+0.1512), cont-novelty (+0.0098), exp-grammar (+0.0297)

### 5. 모델 신뢰성 검증
- 전체 평균 신뢰성 지수 **93.5%**로 실용적 수준 달성
- **인간 평가자 수준 초과**: 모델 성능이 인간 일치도를 1.9% 초과
- 8개 루브릭에서 모델-평가자 일치도가 인간 일치도의 85% 이상

## 🛠️ 향후 개선 방안

### 단기 개선 과제
- **문법/어휘 평가 강화**: 구문 분석기, 품사 태거 등 언어학적 도구 통합
- **도메인 특화 모델**: 문법 오류 탐지 전용 모델과 앙상블 구성
- **추가 하이퍼파라미터 탐색**: 더 정교한 최적화로 0.65+ QWK 목표

### 중장기 연구 방향
- **Transformer 아키텍처** 적용으로 장거리 의존성 포착
- **다중 태스크 학습**으로 루브릭 간 상관관계 활용
- **준지도 학습**을 통한 대규모 미라벨 데이터 활용
- **설명 가능한 AI** 기법으로 채점 근거 제시

### 평가 시스템 개선
- **계층적 평가**: 구조적 → 내용적 → 언어적 순서로 단계별 평가
- **앙상블 전략**: 루브릭별 특화 모델을 조합한 하이브리드 시스템
- **실시간 피드백**: 학습자를 위한 즉시 피드백 시스템 구축

## 📄 License

이 프로젝트는 연구 목적으로 개발되었습니다.

---

*개발자: [Ganghee Go] | 최종 업데이트: 2025년 8월*
